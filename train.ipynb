{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as L\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>stack_depth</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((()()())())()(())()(()(()))()((()()(((()((()(...</td>\n",
       "      <td>-40</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>()()()()()()(())()()((()((((()))()())()(()()))...</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((()()())()()())()(()(((()()()()()))))(((())))...</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>()((()(()()(()())))())(())(((()(()))(()((()))(...</td>\n",
       "      <td>-80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>()(((()()()))((()()()()))((()())()()()))((()()...</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  stack_depth  count\n",
       "0  ((()()())())()(())()(()(()))()((()()(((()((()(...          -40     -2\n",
       "1  ()()()()()()(())()()((()((((()))()())()(()()))...           -8      2\n",
       "2  ((()()())()()())()(()(((()()()()()))))(((())))...           -5     -2\n",
       "3  ()((()(()()(()())))())(())(((()(()))(()((()))(...          -80      2\n",
       "4  ()(((()()()))((()()()()))((()())()()()))((()()...           -4      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from csv\n",
    "brackets = pd.read_csv('Data/stack-depth-train.csv')\n",
    "brackets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader for training\n",
    "encode_dict = {'(': [1, 0, 0, 0], ')': [0, 1, 0, 0], '&': [0, 0, 1, 0], '-': [0, 0, 0, 1]}\n",
    "\n",
    "class BracketDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.X = data['sequence'].values\n",
    "        self.stack_depth = data['stack_depth'].values\n",
    "        self.Y = np.array([[0, 1] if int(y) > 0 else [1, 0] for y in self.stack_depth])\n",
    "        self.stack_depth = np.abs(self.stack_depth)\n",
    "        \n",
    "        self.max_len = max([len(seq) for seq in self.X])\n",
    "        self.eos_index = np.array([len(seq) for seq in self.X])\n",
    "\n",
    "        self.X_encoded = np.array([self.encode_sequence(self.pad_sequence(seq)) for seq in self.X])\n",
    "        \n",
    "    def encode_sequence(self, seq):\n",
    "        return np.array([encode_dict[c] for c in seq])\n",
    "    \n",
    "    def pad_sequence(self, seq):\n",
    "        return seq + '&' + '-' * (self.max_len - len(seq))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'x': self.X_encoded[idx], 'y': self.Y[idx], 'eos': self.eos_index[idx], 'sd': self.stack_depth[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracket = BracketDataset(brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 0]]),\n",
       " 'y': array([1, 0]),\n",
       " 'eos': 512,\n",
       " 'sd': 40}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"Positional Encoding.\n",
    "\n",
    "        Args:\n",
    "            d_model: Hidden dimensionality of the input.\n",
    "            max_len: Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n",
    "        # Used for tensors that need to be on the same device as the module.\n",
    "        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n",
    "        self.register_buffer(\"pe\", pe, persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup, max_iters):\n",
    "        self.warmup = warmup\n",
    "        self.max_num_iters = max_iters\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
    "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr_factor(self, epoch):\n",
    "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n",
    "        if epoch <= self.warmup:\n",
    "            lr_factor *= epoch * 1.0 / self.warmup\n",
    "        return lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        # Stack all weight matrices 1...h together for efficiency\n",
    "        # Note that in many implementations you see \"bias=False\" which is optional\n",
    "        self.qkv_proj = nn.Linear(input_dim, 3 * embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        # Original Transformer initialization, see PyTorch documentation\n",
    "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        self.qkv_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        qkv = self.qkv_proj(x)\n",
    "\n",
    "        # Separate Q, K, V from linear output\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3 * self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3)  # [Batch, Head, SeqLen, Dims]\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # Determine value outputs\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0, 2, 1, 3)  # [Batch, SeqLen, Head, Dims]\n",
    "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
    "        o = self.o_proj(values)\n",
    "\n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        \"\"\"EncoderBlock.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Dimensionality of the input\n",
    "            num_heads: Number of heads to use in the attention block\n",
    "            dim_feedforward: Dimensionality of the hidden layer in the MLP\n",
    "            dropout: Dropout probability to use in the dropout layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Attention layer\n",
    "        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n",
    "\n",
    "        # Two-layer MLP\n",
    "        self.linear_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, dim_feedforward),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim_feedforward, input_dim),\n",
    "        )\n",
    "\n",
    "        # Layers to apply in between the main layers\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Attention part\n",
    "        attn_out = self.self_attn(x, mask=mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # MLP part\n",
    "        linear_out = self.linear_net(x)\n",
    "        x = x + self.dropout(linear_out)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, **block_args):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        return x\n",
    "\n",
    "    def get_attention_maps(self, x, mask=None):\n",
    "        attention_maps = []\n",
    "        for layer in self.layers:\n",
    "            _, attn_map = layer.self_attn(x, mask=mask, return_attention=True)\n",
    "            attention_maps.append(attn_map)\n",
    "            x = layer(x)\n",
    "        return attention_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outbeddings = []\n",
    "val_outbeddings = []\n",
    "test_outbeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPredictor(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        model_dim,\n",
    "        num_classes,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        lr,\n",
    "        warmup,\n",
    "        max_iters,\n",
    "        dropout=0.0,\n",
    "        input_dropout=0.0,\n",
    "    ):\n",
    "        \"\"\"TransformerPredictor.\n",
    "\n",
    "        Args:\n",
    "            input_dim: Hidden dimensionality of the input\n",
    "            model_dim: Hidden dimensionality to use inside the Transformer\n",
    "            num_classes: Number of classes to predict per sequence element\n",
    "            num_heads: Number of heads to use in the Multi-Head Attention blocks\n",
    "            num_layers: Number of encoder blocks to use.\n",
    "            lr: Learning rate in the optimizer\n",
    "            warmup: Number of warmup steps. Usually between 50 and 500\n",
    "            max_iters: Number of maximum iterations the model is trained for. This is needed for the CosineWarmup scheduler\n",
    "            dropout: Dropout to apply inside the model\n",
    "            input_dropout: Dropout to apply on the input features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self._create_model()\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task=\"binary\")\n",
    "\n",
    "    def _create_model(self):\n",
    "        # Input dim -> Model dim\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Dropout(self.hparams.input_dropout), nn.Linear(self.hparams.input_dim, self.hparams.model_dim)\n",
    "        )\n",
    "        # Positional encoding for sequences\n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.hparams.model_dim)\n",
    "        # Transformer\n",
    "        self.transformer = TransformerEncoder(\n",
    "            num_layers=self.hparams.num_layers,\n",
    "            input_dim=self.hparams.model_dim,\n",
    "            dim_feedforward=2 * self.hparams.model_dim,\n",
    "            num_heads=self.hparams.num_heads,\n",
    "            dropout=self.hparams.dropout,\n",
    "        )\n",
    "        # Output classifier per sequence element\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.model_dim),\n",
    "            nn.LayerNorm(self.hparams.model_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(self.hparams.dropout),\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, data, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input features of shape [Batch, SeqLen, input_dim]\n",
    "            mask: Mask to apply on the attention outputs (optional)\n",
    "            add_positional_encoding: If True, we add the positional encoding to the input.\n",
    "                                      Might not be desired for some tasks.\n",
    "        \"\"\"\n",
    "        x = data['x'].float()\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        outbedding = self.transformer(x, mask=mask)\n",
    "        x = self.output_net(outbedding)\n",
    "        return x, outbedding\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_attention_maps(self, data, mask=None, add_positional_encoding=True):\n",
    "        \"\"\"Function for extracting the attention matrices of the whole Transformer for a single batch.\n",
    "\n",
    "        Input arguments same as the forward pass.\n",
    "        \"\"\"\n",
    "        x = data['x']\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n",
    "        return attention_maps\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "        # We don't return the lr scheduler because we need to apply it per iteration, not per epoch\n",
    "        self.lr_scheduler = CosineWarmupScheduler(\n",
    "            optimizer, warmup=self.hparams.warmup, max_iters=self.hparams.max_iters\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def optimizer_step(self, *args, **kwargs):\n",
    "        super().optimizer_step(*args, **kwargs)\n",
    "        self.lr_scheduler.step()  # Step per iteration\n",
    "        \n",
    "    def calc_loss(self, batch, mode='train'):\n",
    "        x, y = batch['x'], batch['y'].float()\n",
    "        eos = batch['eos']\n",
    "        batch['x'] = batch['x'].float()\n",
    "        y_hat, outbeds = self(batch)\n",
    "        y_hat = y_hat[torch.arange(y_hat.size(0)), eos]\n",
    "        outbeds = outbeds[torch.arange(outbeds.size(0)), eos]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        accuracy = self.accuracy(F.softmax(y_hat), y)\n",
    "        return loss, accuracy, outbeds\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, accuracy, outbeds = self.calc_loss(batch, 'train')\n",
    "        train_outbeddings.append([outbeds.cpu(), batch['sd']])\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', accuracy, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, accuracy, outbeds = self.calc_loss(batch, 'val')\n",
    "        val_outbeddings.append([outbeds.cpu(), batch['sd']])\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', accuracy, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, accuracy, outbeds = self.calc_loss(batch, 'test')\n",
    "        test_outbeddings.append([outbeds.cpu(), batch['sd']])\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', accuracy, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def get_outbeddings(self):\n",
    "        return self.outbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide bracket into train test and val\n",
    "bracket_size = len(bracket)\n",
    "train_size = int(0.8 * bracket_size)\n",
    "val_size = int(0.1 * bracket_size)\n",
    "test_size = bracket_size - train_size - val_size\n",
    "\n",
    "train_bracket, val_bracket, test_bracket = torch.utils.data.random_split(bracket, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_bracket, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_bracket, batch_size=64)\n",
    "test_loader = DataLoader(test_bracket, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | input_net           | Sequential         | 640   \n",
      "1 | positional_encoding | PositionalEncoding | 0     \n",
      "2 | transformer         | TransformerEncoder | 132 K \n",
      "3 | output_net          | Sequential         | 17.0 K\n",
      "4 | accuracy            | BinaryAccuracy     | 0     \n",
      "-----------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.601     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f126b0ce276646f8a39ae2d421942ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshitsinha3/Library/CloudStorage/OneDrive-InternationalInstituteofInformationTechnology/3-2/RSAI/Mechanistic_Interpretability/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/var/folders/5b/1q9_lqrs79ng7n9hjm_xl4cm0000gn/T/ipykernel_85245/184518823.py:108: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  accuracy = self.accuracy(F.softmax(y_hat), y)\n",
      "/Users/akshitsinha3/Library/CloudStorage/OneDrive-InternationalInstituteofInformationTechnology/3-2/RSAI/Mechanistic_Interpretability/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e105e2f0324309a628fb81e20d815e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d3491b2c8d4f799ce733d0c217736e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1c5c51d47547a89e912e356c5b5743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TransformerPredictor(input_dim=4, model_dim=128, num_classes=2, num_heads=4, num_layers=1, lr=1e-3, warmup=100, max_iters=1000)\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_outbeddings), train_outbeddings[0][0].shape, train_outbeddings[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outbeddings = [(x.cpu(), y.cpu()) for x, y in train_outbeddings]\n",
    "val_outbeddings = [(x.cpu(), y.cpu()) for x, y in val_outbeddings]\n",
    "test_outbeddings = [(x.cpu(), y.cpu()) for x, y in test_outbeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_batch_dimension(outbeddings, stack_depths=[5, 15]):\n",
    "    outbeds = torch.cat([x[0] for x in outbeddings], dim=0)\n",
    "    depths = torch.cat([x[1] for x in outbeddings])\n",
    "\n",
    "    indices = torch.where(torch.isin(depths, torch.tensor(stack_depths)))[0]\n",
    "\n",
    "    outbeds = outbeds[indices]\n",
    "    depths = depths[indices]\n",
    "\n",
    "    return outbeds, depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_probe, Y_train_probe =  remove_batch_dimension(train_outbeddings)\n",
    "X_val_probe, Y_val_probe =  remove_batch_dimension(val_outbeddings)\n",
    "X_test_probe, Y_test_probe =  remove_batch_dimension(test_outbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_probe.shape, Y_train_probe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_probe_loader = DataLoader(TensorDataset(X_train_probe.cpu(), Y_train_probe.cpu()), batch_size=64, shuffle=True)\n",
    "X_val_probe_loader = DataLoader(TensorDataset(X_val_probe.cpu(), Y_val_probe.cpu()), batch_size=64)\n",
    "X_test_probe_loader = DataLoader(TensorDataset(X_test_probe.cpu(), Y_test_probe.cpu()), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLPRegressor(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(MLPRegressor, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.activation = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.activation(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "    \n",
    "#     def train_model(self, X_train, y_train, num_epochs=10, batch_size=32, learning_rate=0.01):\n",
    "#         criterion = nn.MSELoss()\n",
    "#         optimizer = optim.AdamW(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "#         X_train = X_train.cpu().float()\n",
    "#         y_train = y_train.cpu().float()\n",
    "        \n",
    "#         for epoch in range(num_epochs):\n",
    "#             for inputs, targets in zip(X_train, y_train):\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = self(inputs)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "#                 loss.backward(retain_graph=True)\n",
    "#                 optimizer.step()\n",
    "#             print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "#         print(\"Training finished.\")\n",
    "\n",
    "#     def test_model(self, X_test, y_test):\n",
    "#         test_dataset = TensorDataset(X_test.cpu())\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "        \n",
    "#         predictions = []\n",
    "#         with torch.no_grad():\n",
    "#             for inputs in test_loader:\n",
    "#                 outputs = self(inputs[0])\n",
    "#                 predictions.extend(outputs.tolist())\n",
    "        \n",
    "#         predictions = np.array(predictions)\n",
    "#         print(f'MSE: {mean_squared_error(y_test.cpu().float(), predictions):.4f}')\n",
    "#         print(f'MAE: {mean_absolute_error(y_test, predictions):.4f}')\n",
    "#         print(f'R2: {r2_score(y_test, predictions):.4f}')\n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_probe = MLPRegressor(input_dim=128, hidden_dim=64, output_dim=1)\n",
    "# mlp_probe.train_model(X_train_probe, Y_train_probe, num_epochs=10, batch_size=32, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# import decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probe = LogisticRegression()\n",
    "probe.fit(X_train_probe.cpu().detach().numpy(), Y_train_probe.cpu().detach().numpy())\n",
    "\n",
    "preds = probe.predict(X_test_probe.cpu().detach().numpy())\n",
    "\n",
    "print(classification_report(Y_test_probe.cpu().detach().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = DecisionTreeClassifier()\n",
    "probe.fit(X_train_probe.cpu().detach().numpy(), Y_train_probe.cpu().detach().numpy())\n",
    "\n",
    "preds = probe.predict(X_test_probe.cpu().detach().numpy())\n",
    "\n",
    "print(classification_report(Y_test_probe.cpu().detach().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = MLPClassifier(hidden_layer_sizes=(64,), max_iter=1000)\n",
    "probe.fit(X_train_probe.cpu().detach().numpy(), Y_train_probe.cpu().detach().numpy())\n",
    "\n",
    "preds = probe.predict(X_test_probe.cpu().detach().numpy())\n",
    "\n",
    "print(classification_report(Y_test_probe.cpu().detach().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = MLPClassifier(hidden_layer_sizes=(64,128), max_iter=1000)\n",
    "probe.fit(X_train_probe.cpu().detach().numpy(), Y_train_probe.cpu().detach().numpy())\n",
    "\n",
    "preds = probe.predict(X_test_probe.cpu().detach().numpy())\n",
    "\n",
    "print(classification_report(Y_test_probe.cpu().detach().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca on outbeddings\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train_probe_pca = pca.fit_transform(X_train_probe.cpu().detach().numpy())\n",
    "\n",
    "plt.scatter(X_train_probe_pca[:, 0], X_train_probe_pca[:, 1], c=Y_train_probe.cpu().detach().numpy(), cmap='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
